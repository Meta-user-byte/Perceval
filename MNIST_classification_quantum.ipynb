{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST with a simple model and quantum embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by:  https://www.kaggle.com/code/geekysaint/solving-mnist-using-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# for the Boson Sampler\n",
    "import perceval as pcvl\n",
    "#import perceval.providers.scaleway as scw  # Uncomment to allow running on scaleway\n",
    "\n",
    "# for the machine learning model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from boson_sampler import BosonSampler\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "from model import MnistModel, evaluate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Boson Sampler"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bs = BosonSampler(30, 2)\n",
    "bs.embedding_size"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Dataset : a subset of MNIST dataset"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Training loop"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# training loop\n",
    "def fit(epochs, lr, model, train_loader, val_loader, bs: BosonSampler, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    # creation of empty lists to store the training metrics\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        training_losses, training_accs = 0, 0\n",
    "        ## Training Phase\n",
    "        for step, batch in enumerate(tqdm(train_loader)):\n",
    "            # embedding in the BS\n",
    "            if model.embedding_size:\n",
    "                images, labs = batch\n",
    "                images = images.squeeze(0).squeeze(0)\n",
    "                t_s = time.time()\n",
    "                embs = bs.embed(images,1000)\n",
    "                loss,acc = model.training_step(batch,emb = embs.unsqueeze(0))\n",
    "\n",
    "            else:\n",
    "                loss,acc = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            training_losses+=int(loss.detach())\n",
    "            training_accs+=int(acc.detach())\n",
    "            if model.embedding_size and step%100==0:\n",
    "                print(f\"STEP {step}, Training-acc = {training_accs/(step+1)}, Training-losses = {training_losses/(step+1)}\")\n",
    "        \n",
    "        ## Validation phase\n",
    "        result = evaluate(model, val_loader, bs)\n",
    "        validation_loss, validation_acc = result['val_loss'], result['val_acc']\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "        ## summing up all the training and validation metrics\n",
    "        training_loss = training_losses/len(train_loader)\n",
    "        training_accs = training_accs/len(train_loader)\n",
    "        train_loss.append(training_loss)\n",
    "        train_acc.append(training_accs)\n",
    "        val_loss.append(validation_loss)\n",
    "        val_acc.append(validation_acc)\n",
    "\n",
    "        # plot training curves\n",
    "        plot_training_metrics(train_acc,val_acc,train_loss,val_loss)\n",
    "    return(history)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Model training"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# definition of the BosonSampler\n",
    "# here, we use 30 photons and 2 modes\n",
    "\n",
    "bs = BosonSampler(30, 2, postselect = 2, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}, and embedding size = {bs.embedding_size}\")\n",
    "\n",
    "#to display it\n",
    "pcvl.pdisplay(bs.create_circuit())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# define device to run the model\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE = {device}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# define the model and send it to the appropriate device\n",
    "# set embedding_size = bs.embedding_size if you want to use the boson sampler in input of the model\n",
    "model = MnistModel(device = device)\n",
    "#model = MnistModel(device = device, embedding_size = bs.embedding_size)\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 5, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# end session if needed\n",
    "if session is not None:\n",
    "    session.stop()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
